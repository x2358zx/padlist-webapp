import os
import io
import uuid
import zipfile
from typing import List, Optional, Dict, Any

from fastapi import FastAPI, Request, UploadFile, File, Form
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse, RedirectResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates

from openpyxl import load_workbook
from openpyxl.utils.cell import coordinate_from_string
from openpyxl.utils import get_column_letter
from PIL import Image

import json
import posixpath as pp
import xml.etree.ElementTree as ET
import re

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_DIR = os.path.join(BASE_DIR, "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

app = FastAPI()
app.mount("/static", StaticFiles(directory=os.path.join(BASE_DIR, "static")), name="static")
templates = Jinja2Templates(directory=os.path.join(BASE_DIR, "templates"))

# === èº«åˆ†/ç’°å¢ƒè¨­å®šï¼ˆä»¥ç’°å¢ƒè®Šæ•¸ç‚ºä¸»ï¼‰ ===
TRUST_PROXY = os.getenv("TRUST_PROXY", "1") == "1"
DEPLOY_ENV = os.getenv("DEPLOY_ENV", "test")
SUPERVISOR_USERS = [u.strip() for u in os.getenv("SUPERVISOR_USERS", "").split(",") if u.strip()]
ALLOWED_EDITOR_IPS = [ip.strip() for ip in os.getenv("ALLOWED_EDITOR_IPS", "").split(",") if ip.strip()]
DEV_ALLOW_LOCAL_EDITOR = os.getenv("DEV_ALLOW_LOCAL_EDITOR", "1") == "1"

def get_client_ip(request: Request) -> str:
    """
    å¾ X-Forwarded-For / X-Real-IPï¼ˆåœ¨ nginx è¨­å®šï¼‰æˆ– fallback åˆ° request.client.host å–å¾—ä¾†æº IP
    """
    if TRUST_PROXY:
        xff = request.headers.get("x-forwarded-for")
        if xff:
            # å–æœ€å‰é¢é‚£å€‹ï¼ˆæœ€æ¥è¿‘å®¢æˆ¶ç«¯ï¼‰
            return xff.split(",")[0].strip()
        xri = request.headers.get("x-real-ip")
        if xri:
            return xri.strip()
    # æ²’ä»£ç†æˆ–æ²’æ¨™é ­æ™‚
    return (request.client.host if request.client else "") or ""

def is_editor(request: Request) -> bool:
    """
    ä¼ºæœç«¯æ¬Šé™åˆ¤æ–·ï¼ˆIP / AD ä½¿ç”¨è€…ï¼‰
    è¦å‰‡ï¼š
    1) è‹¥æœ‰ AD ä½¿ç”¨è€…ï¼ˆX-Remote-Userï¼‰ï¼Œä¸”åœ¨ SUPERVISOR_USERS æ¸…å–®ä¸­ â†’ é€šé
    2) ä¾†æº IP åœ¨ ALLOWED_EDITOR_IPS â†’ é€šé
    3) æœ¬æ©Ÿ/é–‹ç™¼æ¸¬è©¦ï¼šDEV_ALLOW_LOCAL_EDITOR=1 ä¸” IP ç‚º 127.0.0.1 / ::1 â†’ é€šé
    """
    ip = get_client_ip(request)
    user = request.headers.get("X-Remote-User") or request.headers.get("Remote-User")

    if user and SUPERVISOR_USERS and user in SUPERVISOR_USERS:
        return True
    if ip and ALLOWED_EDITOR_IPS and ip in ALLOWED_EDITOR_IPS:
        return True
    if DEV_ALLOW_LOCAL_EDITOR and ip in ("127.0.0.1", "::1"):
        return True
    return False

@app.get("/me")
async def me(request: Request):
    """
    å›å‚³å‰ç«¯éœ€è¦çš„èº«åˆ†è³‡è¨Šï¼Œè®“å‰ç«¯æ±ºå®šæ˜¯å¦é–‹å•Ÿç·¨è¼¯ UI
    """
    ip = get_client_ip(request)
    user = request.headers.get("X-Remote-User") or request.headers.get("Remote-User")
    return JSONResponse({
        "client_ip": ip,
        "user": user,
        "env": DEPLOY_ENV,
        "is_editor": is_editor(request)
    })


@app.get("/favicon.ico")
async def favicon():
    return RedirectResponse(url="/static/app.ico")

# === æ–°å¢ï¼šå°‡æª”åå®‰å…¨åŒ–ï¼ˆç”¨æ–¼è¼¸å‡ºåœ–æª”ï¼‰===
def _safe_name(name: str) -> str:
    keep = "-_.()[]{}+@ï¼@å…¨å½¢ä¹Ÿå¯ç”¨"
    return "".join(ch if ch.isalnum() or ch in keep else "_" for ch in name).strip("_") or "sheet"

# === æ–°å¢ï¼šå»ºæ§‹ã€Œæ¯å€‹å·¥ä½œè¡¨ â†’ æœ€å¤§å¼µåœ–ç‰‡ã€å°æ‡‰è¡¨ï¼Œä¸¦æŠŠåœ–ç‰‡è§£å‡ºä¾†åˆ° session ç›®éŒ„ ===
def _build_sheet_image_map(xlsx_path: str, out_dir: str):
    """
    å›å‚³:
      (ordered_sheet_names, map_name_to_saved_path)
      - ordered_sheet_names: ä¾ workbook sheets åŸå§‹é †åºçš„åç¨±æ¸…å–®
      - map_name_to_saved_path: {sheet_name: /abs/save/path/of/largest_image}
    è¦å‰‡ï¼š
      - åªæŒ‘æ¯å¼µå·¥ä½œè¡¨é¢ç©æœ€å¤§çš„åœ–ç‰‡ï¼ˆç”¨ cx*cy ä¼°ç®—ï¼‰
      - è‹¥è©²è¡¨æ²’æœ‰åœ–ç‰‡ï¼Œç•¥éï¼ˆä¸é€²ä¸‹æ‹‰ï¼‰
      - è‹¥ç„¡å°ºå¯¸è³‡è¨Šï¼Œé€€å›ç¬¬ä¸€å¼µ
    """
    with zipfile.ZipFile(xlsx_path, "r") as zf:
        # 1) è§£æ workbook.xmlï¼Œå–å¾— sheet name èˆ‡ rid
        wbk_xml = "xl/workbook.xml"
        wbk_rels = "xl/_rels/workbook.xml.rels"
        ns = {
            "main": "http://schemas.openxmlformats.org/spreadsheetml/2006/main",
            "r": "http://schemas.openxmlformats.org/officeDocument/2006/relationships",
            "xdr": "http://schemas.openxmlformats.org/drawingml/2006/spreadsheetDrawing",
            "a": "http://schemas.openxmlformats.org/drawingml/2006/main",
            "pr": "http://schemas.openxmlformats.org/package/2006/relationships",
        }
        sheets_order = []
        wtree = ET.fromstring(zf.read(wbk_xml))
        for s in wtree.findall(".//main:sheets/main:sheet", ns):
            sheets_order.append((s.attrib.get("name",""), s.attrib.get("{%s}id" % ns["r"], "")))

        # 2) rId â†’ worksheet è·¯å¾‘
        rid_to_ws = {}
        rtree = ET.fromstring(zf.read(wbk_rels))
        for rel in rtree.findall(".//pr:Relationship", ns):
            rid = rel.attrib.get("Id","")
            tgt = rel.attrib.get("Target","")
            # target é€šå¸¸åƒ "worksheets/sheet1.xml"
            rid_to_ws[rid] = pp.normpath(pp.join("xl", tgt))

        # 3) worksheet â†’ drawing â†’ imagesï¼ŒæŒ‘æœ€å¤§å¼µ
        name_to_saved = {}
        for sheet_name, rid in sheets_order:
            ws_path = rid_to_ws.get(rid)
            if not ws_path or ws_path not in zf.namelist():
                continue

            # æ‰¾é€™å¼µå·¥ä½œè¡¨çš„ relsï¼Œè£¡é¢æœƒæœ‰ drawing
            ws_rels = pp.normpath(pp.join("xl/worksheets/_rels", pp.basename(ws_path) + ".rels"))
            if ws_rels not in zf.namelist():
                continue

            wsrels_tree = ET.fromstring(zf.read(ws_rels))
            drawing_target = None
            for rel in wsrels_tree.findall(".//pr:Relationship", ns):
                if rel.attrib.get("Type","").endswith("/drawing"):
                    drawing_target = rel.attrib.get("Target","")  # ex: "../drawings/drawing1.xml"
                    break
            if not drawing_target:
                continue

            drawing_xml = pp.normpath(pp.join(pp.dirname(ws_path), drawing_target))  # â†’ xl/drawings/drawing1.xml
            if drawing_xml not in zf.namelist():
                continue

            # drawing çš„ relsï¼šæŠŠ r:embed â†’ å½±åƒæª”è·¯å¾‘å°ä¸Š
            drawing_rels = pp.normpath(pp.join(pp.dirname(drawing_xml), "_rels", pp.basename(drawing_xml) + ".rels"))
            if drawing_rels not in zf.namelist():
                continue
            drels_tree = ET.fromstring(zf.read(drawing_rels))
            embed_to_media = {}
            for rel in drels_tree.findall(".//pr:Relationship", ns):
                if rel.attrib.get("Type","").endswith("/image"):
                    rid_img = rel.attrib.get("Id","")
                    tgt_img = rel.attrib.get("Target","")  # ex: "../media/image1.png"
                    media_path = pp.normpath(pp.join(pp.dirname(drawing_xml), tgt_img))  # â†’ xl/media/image1.png
                    embed_to_media[rid_img] = media_path

            # è§£æ drawing.xml æ‰¾å‡ºæ‰€æœ‰åœ–ç‰‡çš„ a:blipï¼ˆæ‹¿ r:embedï¼‰èˆ‡ a:extï¼ˆæ‹¿ cx, cyï¼‰
            dtree = ET.fromstring(zf.read(drawing_xml))
            candidates = []  # [(area, embed_id)]
            for pic in dtree.findall(".//xdr:pic", ns):
                blip = pic.find(".//a:blip", ns)
                if blip is None:
                    continue
                embed_id = blip.attrib.get("{%s}embed" % ns["r"])
                # å˜—è©¦æŠ“å°ºå¯¸ï¼ˆæœ‰äº›æª”å¯èƒ½æ²’æœ‰ extï¼‰
                ext = pic.find(".//a:xfrm/a:ext", ns)
                try:
                    cx = int(ext.attrib.get("cx","0")) if ext is not None else 0
                    cy = int(ext.attrib.get("cy","0")) if ext is not None else 0
                except Exception:
                    cx = cy = 0
                area = cx * cy
                candidates.append((area, embed_id))

            if not candidates:
                continue
            # ä¾é¢ç©æŒ‘æœ€å¤§ï¼›è‹¥éƒ½ 0ï¼Œé€™å€‹æ’åºä¹Ÿæœƒä¿ç•™ç¬¬ä¸€å¼µ
            candidates.sort(key=lambda t: t[0], reverse=True)
            _, best_embed = candidates[0]
            media_rel = embed_to_media.get(best_embed)
            if not media_rel or media_rel not in zf.namelist():
                continue

            # å¯«å‡ºæª”æ¡ˆåˆ° session ç›®éŒ„
            ext = os.path.splitext(media_rel)[1].lower() or ".png"
            out_name = f"{_safe_name(sheet_name)}_largest{ext}"
            out_path = os.path.join(out_dir, out_name)
            with open(out_path, "wb") as f:
                f.write(zf.read(media_rel))

            name_to_saved[sheet_name] = out_path

        # åªæœ‰ã€Œæœ‰åœ–ã€çš„å·¥ä½œè¡¨éœ€è¦åˆ—å…¥é¸å–®
        ordered_names_with_image = [nm for nm, _ in sheets_order if nm in name_to_saved]
        return ordered_names_with_image, name_to_saved

def _sheet_has_data(ws) -> bool:
    """Heuristic: if any cell in the used range has a non-empty value."""
    try:
        min_row = 1
        max_row = ws.max_row or 0
        min_col = 1
        max_col = ws.max_column or 0
        max_row = min(max_row, 200)
        max_col = min(max_col, 50)
        for r in range(min_row, max_row + 1):
            for c in range(min_col, max_col + 1):
                if ws.cell(row=r, column=c).value not in (None, ""):
                    return True
        return False
    except Exception:
        return False

def _read_cell_text(ws, cell_addr: str) -> str:
    try:
        value = ws[cell_addr].value
        if value not in (None, ""):
            return str(value)
        # è‹¥ç©ºï¼Œå˜—è©¦å¾åˆä½µå„²å­˜æ ¼å–å€¼
        target_col_letter, target_row = coordinate_from_string(cell_addr)
        target_col_idx = ws[cell_addr].column  # numeric
        for mr in ws.merged_cells.ranges:
            min_col, min_row, max_col, max_row = mr.bounds
            # èˆ‡ WPF ç›¸åŒé‚è¼¯ï¼šåŒåˆ—ã€ä¸”ç›®æ¨™æ¬„åœ¨åˆä½µç¯„åœå…§
            if min_row == int(target_row) and min_col <= target_col_idx <= max_col:
                v = ws.cell(row=min_row, column=min_col).value
                if v not in (None, ""):
                    return str(v)
    except Exception:
        pass
    return ""

# === è‡ªå‹•åµæ¸¬å°å·¥å…·ï¼ˆä¸­æ–‡è¨»è§£ï¼‰ ===
def _scan_text(ws, max_rows=120, max_cols=40):
    """æŠŠå‰ max_rows Ã— max_cols çš„å„²å­˜æ ¼æƒä¸€éï¼Œå›å‚³ (r,c,æ–‡å­—) çš„ç”Ÿæˆå™¨ã€‚"""
    for r in range(1, max_rows + 1):
        for c in range(1, max_cols + 1):
            v = ws.cell(row=r, column=c).value
            if v not in (None, ""):
                yield r, c, str(v).strip()

def _find_cell(ws, keywords, **kw):
    """åœ¨é é¢å·¦ä¸Šè§’å€åŸŸæ‰¾ã€åŒ…å« keywords ä»»ä¸€é—œéµå­—ã€çš„å„²å­˜æ ¼ã€‚
    å›å‚³ (row, col)ï¼›å¤šç­†æ™‚æ¡ã€æœ€é ä¸Šã€å†æœ€é å·¦ã€çš„é‚£ä¸€æ ¼ã€‚"""
    if isinstance(keywords, str):
        keywords = [keywords]
    kws = [k.lower() for k in keywords]
    best = None
    for r, c, s in _scan_text(ws, **kw):
        s_low = s.lower()
        if any(k in s_low for k in kws):
            if best is None or (r < best[0] or (r == best[0] and c < best[1])):
                best = (r, c)
    return best

# æ–‡å­—æ­£è¦åŒ–ï¼šå»æ‰éè‹±æ•¸ï¼Œè½‰å°å¯«ï¼Œä¾¿æ–¼æ¯”å°ã€Œç­‰æ–¼ã€
def _norm(s: str) -> str:
    return re.sub(r'[^a-z0-9]+', '', s.lower()) if s else ''

def _find_header_exact(ws, patterns, **kw):
    """
    æ‰¾ã€å®Œå…¨ç­‰æ–¼ã€å…¶ä¸­ä¸€å€‹ patternï¼ˆæ¯”å°ç”¨ _normï¼‰
    ä¾‹å¦‚ï¼špatterns=["pin", "pinno", "pin#"]ï¼Œå°±ä¸æœƒæŠŠ "Pin Name" èª¤åˆ¤æˆ "Pin"
    """
    pats = [_norm(p) for p in (patterns if isinstance(patterns, (list, tuple)) else [patterns])]
    best = None
    for r, c, s in _scan_text(ws, **kw):
        if _norm(s) in pats:
            if best is None or (r < best[0] or (r == best[0] and c < best[1])):
                best = (r, c)
    return best


def _col_letter(cidx: int) -> str:
    from openpyxl.utils import get_column_letter
    return get_column_letter(cidx)

def _find_header_exact_in_row(ws, patterns, row, col_from=1, col_to=None):
    """åªåœ¨ row é€™ä¸€åˆ—æ‰¾ã€å®Œå…¨ç­‰æ–¼ patterns ä¹‹ä¸€ã€çš„è¡¨é ­ã€‚æœƒå›å‚³ (row, col)ã€‚"""
    if isinstance(patterns, (list, tuple)):
        pats = [_norm(p) for p in patterns]
    else:
        pats = [_norm(patterns)]
    if row < 1 or row > (ws.max_row or 0):
        return None
    if col_to is None:
        col_to = min(ws.max_column or 0, 100)

    for c in range(max(1, col_from), col_to + 1):
        v = ws.cell(row=row, column=c).value
        if v not in (None, "") and _norm(str(v)) in pats:
            return (row, c)
    return None


def _extract_first_image_from_xlsx(xlsx_path: str, out_dir: str) -> Optional[str]:
    # ç›´æ¥å¾ zip å– xl/media/* ç¬¬ä¸€å¼µ
    try:
        with zipfile.ZipFile(xlsx_path, "r") as zf:
            media_files = [n for n in zf.namelist() if n.startswith("xl/media/") and (n.lower().endswith(".png") or n.lower().endswith(".jpg") or n.lower().endswith(".jpeg"))]
            if not media_files:
                return None
            name = media_files[0]
            data = zf.read(name)
            ext = os.path.splitext(name)[1].lower()
            out_path = os.path.join(out_dir, f"chip_image{ext}")
            with open(out_path, "wb") as f:
                f.write(data)
            return out_path
    except Exception:
        return None

@app.get("/", response_class=HTMLResponse)
async def index(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.post("/upload")
async def upload_excel(file: UploadFile = File(...)):
    try:
        sid = uuid.uuid4().hex[:10]
        sess_dir = os.path.join(UPLOAD_DIR, sid)
        os.makedirs(sess_dir, exist_ok=True)

        saved_path = os.path.join(sess_dir, "workbook.xlsx")
        with open(saved_path, "wb") as f:
            f.write(await file.read())

        # wb = load_workbook(saved_path, data_only=True)
        # sheets = [ws.title for ws in wb.worksheets if _sheet_has_data(ws)]
        # if not sheets:
        #     sheets = list(wb.sheetnames)
        # 
        # img_path = _extract_first_image_from_xlsx(saved_path, sess_dir)
        # img_url = f"/uploads/{sid}/" + os.path.basename(img_path) if img_path else None
        # 
        # return JSONResponse({"session_id": sid, "sheets": sheets, "image_url": img_url})
        # è®€ workbookï¼Œå»ºç«‹ã€Œæ¯è¡¨æœ€å¤§åœ–ã€å°æ‡‰ï¼ˆåªåˆ—å‡ºæœ‰åœ–çš„å·¥ä½œè¡¨ï¼‰
        wb = load_workbook(saved_path, data_only=True)
        sheets_with_img_ordered, map_name_to_saved = _build_sheet_image_map(saved_path, sess_dir)

        # å°‡å°æ‡‰è¡¨å­˜æˆ jsonï¼Œçµ¦ /sheet_info ä½¿ç”¨
        mapping_json = os.path.join(sess_dir, "sheet_images.json")
        with open(mapping_json, "w", encoding="utf-8") as f:
            json.dump({k: os.path.basename(v) for k, v in map_name_to_saved.items()}, f, ensure_ascii=False)

        # é è¨­é¡¯ç¤ºç¬¬ä¸€å€‹æœ‰åœ–çš„å·¥ä½œè¡¨ä¹‹åœ–ç‰‡
        default_image_url = None
        if sheets_with_img_ordered:
            first_sheet = sheets_with_img_ordered[0]
            fname = os.path.basename(map_name_to_saved[first_sheet])
            default_image_url = f"/uploads/{sid}/{fname}"

        return JSONResponse({
            "session_id": sid,
            # åƒ…åŒ…å«ã€Œæœ‰åœ–ã€çš„å·¥ä½œè¡¨ï¼Œå‰ç«¯ä¸‹æ‹‰å°±ä¸æœƒå‡ºç¾æ²’åœ–çš„è¡¨
            "sheets": sheets_with_img_ordered,
            # åˆå§‹åœ–ï¼ˆç¬¬ä¸€å€‹å·¥ä½œè¡¨çš„ã€Œæœ€å¤§å¼µã€ï¼‰
            "default_image_url": default_image_url
        })
    except Exception as e:
        return JSONResponse({"error": f"Failed to read Excel: {type(e).__name__}: {e}"}, status_code=400)

@app.get("/uploads/{sid}/{fname}")
async def serve_upload(sid: str, fname: str):
    path = os.path.join(UPLOAD_DIR, sid, fname)
    if os.path.exists(path):
        return FileResponse(path)
    return JSONResponse({"error": "file not found"}, status_code=404)

@app.post("/sheet_info")
async def sheet_info(
    session_id: str = Form(...),
    sheet_name: str = Form(...),
):
    sess_dir = os.path.join(UPLOAD_DIR, session_id)
    xlsx_path = os.path.join(sess_dir, "workbook.xlsx")
    if not os.path.exists(xlsx_path):
        return JSONResponse({"error": "session not found"}, status_code=404)

    wb = load_workbook(xlsx_path, data_only=True)
    if sheet_name not in wb.sheetnames:
        return JSONResponse({"error": "sheet not found"}, status_code=404)
    ws = wb[sheet_name]

    # === è‡ªå‹•åµæ¸¬ï¼šChip Size / Project Code / PadWindow / CUPï¼ˆä¸­æ–‡è¨»è§£ï¼‰ ===
    # 1) Chip Sizeï¼šæ‰¾å«ã€Œchip sizeã€çš„é—œéµå­—ï¼Œå¾€å³ä¸€æ ¼è®€å–æ–‡å­—ä¸¦è§£æ "123 um x 456 um"
    cs_pos = _find_cell(ws, ["chip size", "chipsize", "chip-size"])
    width = height = None
    if cs_pos:
        r, c = cs_pos
        cell_txt = _read_cell_text(ws, f"{_col_letter(c+1)}{r}")
        m = re.search(r"(\d+\.?\d*)\s*um\s*[XÃ—x]\s*(\d+\.?\d*)\s*um", str(cell_txt))
        if m:
            width = float(m.group(1))
            height = float(m.group(2))

    # 2) Project Codeï¼šæ‰¾åˆ°ã€ŒNameã€é—œéµå­—ï¼Œå¾€å³ä¸€æ ¼
    proj_pos = _find_cell(ws, ["name"])
    project_code = None
    if proj_pos:
        r, c = proj_pos
        project_code = _read_cell_text(ws, f"{_col_letter(c+1)}{r}") or ""

    # 3) PadWindow / CUPï¼šå„è‡ªå¾€å³ä¸€æ ¼ï¼ˆå¯é¸ï¼‰
    padwindow = cup = None
    pw_pos = _find_cell(ws, ["padwindow", "pad window"])
    if pw_pos:
        r, c = pw_pos
        padwindow = _read_cell_text(ws, f"{_col_letter(c+1)}{r}") or ""
    cup_pos = _find_cell(ws, ["cup"])
    if cup_pos:
        r, c = cup_pos
        cup = _read_cell_text(ws, f"{_col_letter(c+1)}{r}") or ""


    # ä¾å·¥ä½œè¡¨å›å‚³å°æ‡‰çš„ã€Œæœ€å¤§å¼µåœ–ç‰‡ã€
    mapping_json = os.path.join(sess_dir, "sheet_images.json")
    img_url = None
    if os.path.exists(mapping_json):
        try:
            with open(mapping_json, "r", encoding="utf-8") as f:
                m = json.load(f)  # {sheet_name: filename}
            fname = m.get(sheet_name)
            if fname:
                img_url = f"/uploads/{session_id}/{fname}"
        except Exception:
            img_url = None

    return JSONResponse({
        "chip_size": {"width": width, "height": height},
        "project_code": project_code,
        "image_url": img_url,
        "extras": {"PadWindow": padwindow, "CUP": cup}
    })

@app.post("/parse_pins")
async def parse_pins(
    session_id: str = Form(...),
    sheet_name: str = Form(...),
):
    sess_dir = os.path.join(UPLOAD_DIR, session_id)
    xlsx_path = os.path.join(sess_dir, "workbook.xlsx")
    if not os.path.exists(xlsx_path):
        return JSONResponse({"error": "session not found"}, status_code=404)

    wb = load_workbook(xlsx_path, data_only=True)
    if sheet_name not in wb.sheetnames:
        return JSONResponse({"error": "sheet not found"}, status_code=404)
    ws = wb[sheet_name]
    if ws.max_row is None or ws.max_row == 0:
        return JSONResponse({"valid_pins": [], "invalid_pins": []})

        # === è‡ªå‹•åµæ¸¬ï¼šPIN / Text Name / X-axis / Y-axis å››å€‹æ¬„ä½ç½®èˆ‡èµ·å§‹åˆ— ===
    # å®¹è¨±ä¸åŒå¯«æ³•ï¼ˆå¤§å°å¯«/ç©ºç™½/ç ´æŠ˜è™Ÿï¼‰
    pin_hdr = _find_header_exact(ws, ["pin", "pinno", "pin#", "pinno."])
    name_hdr = _find_header_exact(ws, ["textname", "pinname", "name"])
    x_hdr   = _find_header_exact(ws, ["xaxis", "x-axis", "x"])
    y_hdr   = _find_header_exact(ws, ["yaxis", "y-axis", "y"])

        # === è®“ Name è¡¨é ­ã€Œé è¿‘ PIN/X/Y æ‰€åœ¨çš„è¡¨é ­åˆ—ã€ ===
    header_row_guess = max(pin_hdr[0], x_hdr[0], y_hdr[0])  # å¤šåŠåŒåˆ—ï¼Œå–æœ€å¤§é‚£åˆ—ç•¶è¡¨é ­åˆ—

    # å…ˆå˜—è©¦ï¼šåªåœ¨é€™ä¸€åˆ—æ‰¾ name è¡¨é ­
    name_near = _find_header_exact_in_row(ws, ["textname", "pinname", "name"], header_row_guess)
    if not name_near:
        # å†æ”¾å¯¬åˆ° Â±2 åˆ—
        for dr in ( -1, 1, -2, 2 ):
            cand = _find_header_exact_in_row(ws, ["textname", "pinname", "name"], header_row_guess + dr)
            if cand:
                name_near = cand
                break
    if name_near:
        name_hdr = name_near

    # è‹¥ name è·Ÿ pin é‚„æ˜¯åœ¨åŒä¸€æ¬„ï¼Œå„ªå…ˆå¾ã€ŒåŒåˆ—è¡¨é ­ã€pin å³é‚Šã€å†æ‰¾ä¸€æ¬¡
    if name_hdr and pin_hdr and name_hdr[1] == pin_hdr[1]:
        cand = _find_header_exact_in_row(ws, ["textname", "pinname", "name"],
                                         header_row_guess, col_from=pin_hdr[1] + 1)
        if cand:
            name_hdr = cand


    # è‹¥ pin_hdr èˆ‡ name_hdr æŒ‡åˆ°åŒä¸€æ ¼ï¼ˆä¾‹å¦‚æ¨™é ­æ˜¯ "Pin Name"ï¼‰
    if pin_hdr and name_hdr and pin_hdr == name_hdr:
        hdr_txt = _read_cell_text(ws, f"{_col_letter(pin_hdr[1])}{pin_hdr[0]}")
        if "name" in (hdr_txt or "").lower():
            # é€™æ ¼æ‡‰è©²æ­¸ã€ŒNameã€ï¼Œé‡æ–°æœã€ŒPin Noã€ä½†é™å®šåªæ‰¾ "PIN/PIN NO/PIN#"
            pin_hdr = _find_header_exact(ws, ["pin", "pinno", "pin#", "pinno."])

    if not (pin_hdr and name_hdr and x_hdr and y_hdr):
        return JSONResponse({"valid_pins": [], "invalid_pins": ["æœªåµæ¸¬åˆ°è¡¨é ­ï¼ˆPIN/Name/X-axis/Y-axisï¼‰"]})
        

    # å–ã€Œæœ€é ä¸‹çš„è¡¨é ­åˆ—ã€+1 ä½œç‚ºè³‡æ–™èµ·å§‹åˆ—ï¼ˆé¿å…è¡¨é ­ä¸åœ¨åŒä¸€åˆ—çš„æƒ…æ³ï¼‰
    start_row = max(pin_hdr[0], name_hdr[0], x_hdr[0], y_hdr[0]) + 1

    from openpyxl.utils import get_column_letter
    col_pin = get_column_letter(pin_hdr[1])
    col_nam = get_column_letter(name_hdr[1])
    col_x   = get_column_letter(x_hdr[1])
    col_y   = get_column_letter(y_hdr[1])

    def read_cell(col_letter: str, row_idx: int) -> str:
        try:
            v = ws[f"{col_letter}{row_idx}"].value
            s = "" if v in (None, "") else str(v)
            # ğŸ†• å»æ‰ NBSP(\u00A0) èˆ‡å…¨å½¢ç©ºç™½(\u3000)ï¼Œå† strip
            return s.replace("\u00A0", "").replace("\u3000", "").strip()
        except Exception:
            return ""

    valid_pins, invalid_pins = [], []

    r = start_row
    while r <= ws.max_row:
        pin_no   = read_cell(col_pin, r)
        pin_name = read_cell(col_nam, r)
        num = lambda s: re.sub(r"[^0-9.+-]", "", (s or ""))
        x_text = num(read_cell(col_x, r))
        y_text = num(read_cell(col_y, r))


        # åœæ­¢æ¢ä»¶ï¼šå››æ¬„éƒ½ç©ºç™½ â†’ çµæŸæƒæ
        if pin_no == "" and pin_name == "" and x_text == "" and y_text == "":
            break

        # === æ±ºå®šé€™åˆ—çš„ã€Œèº«åˆ†ã€ ===
        has_id = (pin_no != "" or pin_name != "")   # ğŸ†• åªè¦ PIN æˆ– NAME æœ‰å…¶ä¸€
        has_xy = (x_text != "" or y_text != "")

        # å…©æ¬„éƒ½ç©ºç™½ï¼Œä½†åº§æ¨™æœ‰æ±è¥¿ â†’ è¦–ç‚ºé›œè¨Šåˆ—ï¼Œç›´æ¥è·³é
        if not has_id and has_xy:
            r += 1
            continue

        # å˜—è©¦æŠŠåº§æ¨™è½‰ float
        try:
            x = float(x_text)
            y = float(y_text)
        except Exception:
            x = y = None

        # å¼·åŒ– NC åµæ¸¬ï¼ˆN/Cã€n câ€¦éƒ½æŠ“å¾—åˆ°ï¼‰
        norm_name = re.sub(r'[^a-z]', '', (pin_name or '').lower())
        is_nc = (norm_name == "nc")

        # === åŠ å…¥ invalid æˆ– valid çš„è¦å‰‡ ===
        if (pin_no == "" or is_nc or x is None or y is None):
            # ğŸ†• åªæœ‰ç•¶ã€Œè‡³å°‘æœ‰ PIN æˆ– NAME å…¶ä¸­ä¸€å€‹ã€æ‰åˆ—å…¥ invalid_pins
            if has_id:
                invalid_pins.append(f"{pin_no}, {(pin_name or '').strip()}")
        else:
            cleaned_name = (pin_name or "").replace(" ", "")
            valid_pins.append({"pin_no": pin_no, "pin_name": cleaned_name, "x": x, "y": y})

        r += 1

    return JSONResponse({"valid_pins": valid_pins, "invalid_pins": invalid_pins})

# === æ³¨æ„äº‹é …ï¼ˆoperation / bondingï¼‰è®€å¯« ===
DEFAULT_NOTES = {
    "operation": "ï¼ˆé è¨­ï¼‰é€™è£¡æ”¾æ“ä½œæ³¨æ„äº‹é …çš„èªªæ˜ï¼Œä¾›ä¸»ç®¡ç·¨è¼¯â€¦",
    "bonding": "ï¼ˆé è¨­ï¼‰é€™è£¡æ”¾ bonding æ³¨æ„äº‹é …çš„èªªæ˜ï¼Œä¾›ä¸»ç®¡ç·¨è¼¯â€¦"
}

@app.get("/notices")
async def get_notices(session_id: str):
    """è®€å–æŸæ¬¡ä¸Šå‚³(session)çš„æ³¨æ„äº‹é …ï¼›è‹¥å°šæœªå»ºç«‹å‰‡å›é è¨­ã€‚"""
    sess_dir = os.path.join(UPLOAD_DIR, session_id)
    path = os.path.join(sess_dir, "notices.json")
    data = DEFAULT_NOTES.copy()
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                saved = json.load(f)
                if isinstance(saved, dict):
                    data.update(saved)  # ä»¥å·²ä¿å­˜å…§å®¹è¦†è“‹é è¨­
        except Exception:
            pass
    return JSONResponse(data)

@app.post("/notices")
async def save_notices(
    request: Request,
    session_id: str = Form(...),
    key: str = Form(...),           # "operation" æˆ– "bonding"
    text: str = Form(...),
):
    """å„²å­˜å–®ä¸€é¡åˆ¥çš„æ³¨æ„äº‹é …ï¼›åªæœ‰ is_editor çš„ä¾†æº IP å¯å¯«å…¥ã€‚"""
    if not is_editor(request):      # ä½ ç¾æœ‰çš„ is_editor() æœƒåˆ¤æ–·ä¾†æº IP & ç’°å¢ƒ
        return JSONResponse({"error": "forbidden"}, status_code=403)
    if key not in ("operation", "bonding"):
        return JSONResponse({"error": "invalid key"}, status_code=400)

    sess_dir = os.path.join(UPLOAD_DIR, session_id)
    os.makedirs(sess_dir, exist_ok=True)
    path = os.path.join(sess_dir, "notices.json")

    data = {}
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f) or {}
        except Exception:
            data = {}

    data[key] = text
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return JSONResponse({"ok": True})
